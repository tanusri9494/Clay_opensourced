{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "def get_google_sheets_service():\n",
    "   print(\"Starting authentication process...\")\n",
    "   try:\n",
    "       # Load credentials from the service account file\n",
    "       credentials = service_account.Credentials.from_service_account_file(\n",
    "           'credentials.json', \n",
    "           scopes=SCOPES\n",
    "       )\n",
    "       print(\"Successfully loaded service account credentials\")\n",
    "       \n",
    "       # Build the service\n",
    "       service = build('sheets', 'v4', credentials=credentials)\n",
    "       print(\"Successfully created Google Sheets service\")\n",
    "       return service\n",
    "       \n",
    "   except Exception as e:\n",
    "       print(f\"Error during authentication: {str(e)}\")\n",
    "       raise\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌐 Web Scraping Functions\n",
    "    It has inbuit scraper to scrape the website content and store it in the google sheet\n",
    "    \n",
    "    NOTE:\n",
    "\n",
    "    1. Google sheets Should have a column named \"organization_website_url\" with the website urls to scrape\n",
    "    2. Google sheets Should have a column named \"website_content\" to store the scraped website content in a single column if not present it will be created.\n",
    "    3. It only scrapes the first 5 subpages of the website and concatenates the content of the subpages to the main page content\n",
    "    4. It also limits the content to 100 words to avoid Wasteing Openai API credits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.parse \n",
    "import urljoin\n",
    "import time\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "def get_google_sheets_service():\n",
    "   print(\"Starting authentication process...\")\n",
    "   try:\n",
    "       # Load credentials from the service account file\n",
    "       credentials = service_account.Credentials.from_service_account_file(\n",
    "           'credentials.json', \n",
    "           scopes=SCOPES\n",
    "       )\n",
    "       print(\"Successfully loaded service account credentials\")\n",
    "       \n",
    "       # Build the service\n",
    "       service = build('sheets', 'v4', credentials=credentials)\n",
    "       print(\"Successfully created Google Sheets service\")\n",
    "       return service\n",
    "       \n",
    "   except Exception as e:\n",
    "       print(f\"Error during authentication: {str(e)}\")\n",
    "       raise\n",
    "\n",
    "def get_subpages(base_url):\n",
    "   \"\"\"Get list of subpages from the main URL\"\"\"\n",
    "   try:\n",
    "       headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "       response = requests.get(base_url, headers=headers, timeout=10)\n",
    "       response.raise_for_status()\n",
    "       \n",
    "       soup = BeautifulSoup(response.text, 'html.parser')\n",
    "       base_domain = urlparse(base_url).netloc\n",
    "       \n",
    "       subpages = set()\n",
    "       for link in soup.find_all('a', href=True):\n",
    "           url = urljoin(base_url, link['href'])\n",
    "           # Only include URLs from same domain and avoid parameters\n",
    "           if urlparse(url).netloc == base_domain and '#' not in url and '?' not in url:\n",
    "               subpages.add(url)\n",
    "               \n",
    "       return list(subpages)\n",
    "   except Exception as e:\n",
    "       print(f\"Error getting subpages for {base_url}: {str(e)}\")\n",
    "       return []\n",
    "   \n",
    "def get_text_from_url(url):\n",
    "   \"\"\"Extract clean text content from a URL\"\"\"\n",
    "   try:\n",
    "       headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "       response = requests.get(url, headers=headers, timeout=10)\n",
    "       response.raise_for_status()\n",
    "       \n",
    "       soup = BeautifulSoup(response.text, 'html.parser')\n",
    "       \n",
    "       # Remove unwanted elements\n",
    "       for element in soup(['script', 'style', 'nav', 'footer', 'header']):\n",
    "           element.decompose()\n",
    "           \n",
    "       # Get text and clean it\n",
    "       text = ' '.join(soup.stripped_strings)\n",
    "       return text.strip()\n",
    "   except Exception as e:\n",
    "       print(f\"Error scraping {url}: {str(e)}\")\n",
    "       return \"\"\n",
    "\n",
    "def scrape_website_content(service, spreadsheet_id):\n",
    "    try:\n",
    "        # Get the existing data\n",
    "        range_name = 'Sheet1'\n",
    "        result = service.spreadsheets().values().get(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=range_name\n",
    "        ).execute()\n",
    "        rows = result.get('values', [])\n",
    "        \n",
    "        if not rows:\n",
    "            print('No data found.')\n",
    "            return\n",
    "        \n",
    "        # Identify or create the website_content column\n",
    "        header = rows[0]\n",
    "        if 'website_content' not in header:\n",
    "            header.append('website_content')\n",
    "            service.spreadsheets().values().update(\n",
    "                spreadsheetId=spreadsheet_id,\n",
    "                range=f'{range_name}!A1',\n",
    "                valueInputOption='RAW',\n",
    "                body={'values': [header]}\n",
    "            ).execute()\n",
    "        \n",
    "        content_col_idx = header.index('website_content')  # Get column index\n",
    "        content_col_name = get_column_letter(content_col_idx + 1)  # Convert to column name\n",
    "        \n",
    "        # Process each row\n",
    "        for i, row in enumerate(rows[1:], start=2):  # Start at row 2 in the sheet\n",
    "            if len(row) > header.index('organization_website_url'):  # Check if URL exists\n",
    "                url = row[header.index('organization_website_url')]\n",
    "                content_exists = (\n",
    "                    len(row) > content_col_idx and row[content_col_idx].strip() != \"\"\n",
    "                )\n",
    "                if url and not content_exists:\n",
    "                    print(f\"Processing row {i}: {url}\")\n",
    "                    if not url.startswith(\"http://\") and not url.startswith(\"https://\"):\n",
    "                        url = f\"http://{url}\"\n",
    "      # Default to HTTP if no protocol is provided\n",
    "                    \n",
    "                    # Scrape website content\n",
    "                    content = get_text_from_url(url)\n",
    "                    words = content.split()\n",
    "                    \n",
    "                    # If content is less than 100 words, try subpages\n",
    "                    if len(words) < 100:\n",
    "                        subpages = get_subpages(url)\n",
    "                        for subpage in subpages[:5]:  # Limit to first 5 subpages\n",
    "                            sub_content = get_text_from_url(subpage)\n",
    "                            content += \" \" + sub_content\n",
    "                            words = content.split()\n",
    "                            if len(words) >= 100:\n",
    "                                break\n",
    "                            time.sleep(0.3)  # Be nice to the server\n",
    "                    \n",
    "                    # Limit content to 100 words\n",
    "                    trimmed_content = \" \".join(words[:100])\n",
    "                    \n",
    "                    # Update the cell for website content\n",
    "                    cell = f\"{content_col_name}{i}\"\n",
    "                    service.spreadsheets().values().update(\n",
    "                        spreadsheetId=spreadsheet_id,\n",
    "                        range=f'Sheet1!{cell}',\n",
    "                        valueInputOption='RAW',\n",
    "                        body={'values': [[trimmed_content]]}\n",
    "                    ).execute()\n",
    "                    \n",
    "                    print(f\"Row {i} updated in column {content_col_name}\")\n",
    "                    time.sleep(0.2)  # Be nice to servers\n",
    "                else:\n",
    "                    print(f\"Skipping row {i}: Content already exists or no URL.\")\n",
    "        \n",
    "        print(\"Website content scraping completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "\n",
    "def get_column_letter(col_idx):\n",
    "    \"\"\"Convert a 1-based column index to a column letter (e.g., 1 -> A, 27 -> AA).\"\"\"\n",
    "    col_letter = \"\"\n",
    "    while col_idx > 0:\n",
    "        col_idx, remainder = divmod(col_idx - 1, 26)\n",
    "        col_letter = chr(65 + remainder) + col_letter\n",
    "    return col_letter\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "   service = get_google_sheets_service()\n",
    "   spreadsheet_id = '1Xr13JkH27PWV-EKrhh65JtAqGAhtUg1PHJ78Qy4Y8uw'\n",
    "   scrape_website_content(service, spreadsheet_id)\n",
    "   \n",
    "#    service = get_subpages('https://www.aircraftinteriorsexpo.com/')\n",
    "#    for subpage in service:\n",
    "#        content = get_text_from_url(subpage)\n",
    "#        print(\"subpage\\n\", content )\n",
    "#    print(\"website content:\\n\",service)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✉️ Email Verification System\n",
    "    # Run this cell below to verify the emails in the sheet.\n",
    "    \n",
    "    NOTE: Google sheets Should have\n",
    "    1. column named \"email\" with emails to verify \n",
    "    2. column named \"verified_email\" to store the verified emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import time\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "def get_google_sheets_service():\n",
    "   print(\"Starting authentication process...\")\n",
    "   try:\n",
    "       # Load credentials from the service account file\n",
    "       credentials = service_account.Credentials.from_service_account_file(\n",
    "           'credentials.json', \n",
    "           scopes=SCOPES\n",
    "       )\n",
    "       print(\"Successfully loaded service account credentials\")\n",
    "       \n",
    "       # Build the service\n",
    "       service = build('sheets', 'v4', credentials=credentials)\n",
    "       print(\"Successfully created Google Sheets service\")\n",
    "       return service\n",
    "       \n",
    "   except Exception as e:\n",
    "       print(f\"Error during authentication: {str(e)}\")\n",
    "       raise\n",
    "   \n",
    "def get_column_letter(col_idx):\n",
    "    \"\"\"Convert a 1-based column index to a column letter (e.g., 1 -> A, 27 -> AA).\"\"\"\n",
    "    col_letter = \"\"\n",
    "    while col_idx > 0:\n",
    "        col_idx, remainder = divmod(col_idx - 1, 26)\n",
    "        col_letter = chr(65 + remainder) + col_letter\n",
    "    return col_letter\n",
    "\n",
    "def verify_email(email):\n",
    "    \"\"\"Verify email using Bouncify API\"\"\"\n",
    "    try:\n",
    "        api_key = \"\"\n",
    "        url = f\"https://api.bouncify.io/v1/verify?apikey={api_key}&email={email}\"\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        print(\"APIresponse:\",result)\n",
    "        # Check if the API call was successful\n",
    "        if not result.get(\"success\"):\n",
    "            return \"Error: \" + result.get(\"result\", \"Unknown error\")\n",
    "            \n",
    "        # Get the verification result\n",
    "        status = result.get(\"result\")\n",
    "        \n",
    "        # Map the API response to verification status\n",
    "        if status == \"deliverable\":\n",
    "            return \"Valid\"\n",
    "        elif status == \"undeliverable\":\n",
    "            return \"Invalid\"\n",
    "        elif status in [\"accept-all\", \"unknown\"]:\n",
    "            return \"Invalid\"  # These could be valid addresses\n",
    "        else:\n",
    "            return f\"Unknown: {status}\"\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        if e.response is not None:\n",
    "            if e.response.status_code == 401:\n",
    "                return \"Error: Invalid API Key\"\n",
    "            elif e.response.status_code == 402:\n",
    "                return \"Error: Insufficient credits\"\n",
    "            elif e.response.status_code == 429:\n",
    "                time.sleep(5)  # Wait 5 seconds if rate limited\n",
    "                return \"Error: Rate limited\"\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "def verify_emails_in_sheet(service, spreadsheet_id):\n",
    "    try:\n",
    "        # Get the existing data\n",
    "        range_name = 'Sheet1'\n",
    "        result = service.spreadsheets().values().get(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=range_name\n",
    "        ).execute()\n",
    "        rows = result.get('values', [])\n",
    "        \n",
    "        if not rows:\n",
    "            print('No data found.')\n",
    "            return\n",
    "            \n",
    "        # Find or create the email verification column\n",
    "        header = rows[0]\n",
    "        if 'verified_email' not in header:\n",
    "            header.append('verified_email')\n",
    "            verified_col_idx = len(header) - 1\n",
    "        else:\n",
    "            verified_col_idx = header.index('verified_email')\n",
    "            \n",
    "        email_col_idx = header.index('email')  # Get email column index\n",
    "        verified_col_name = get_column_letter(verified_col_idx + 1)\n",
    "        \n",
    "        # Process each row\n",
    "        for i, row in enumerate(rows[1:], start=2):\n",
    "            if len(row) > email_col_idx:\n",
    "                email = row[email_col_idx]\n",
    "                if email:\n",
    "                    # First check if the cell already has a verified email\n",
    "                    cell = f\"{verified_col_name}{i}\"\n",
    "                    cell_result = service.spreadsheets().values().get(\n",
    "                        spreadsheetId=spreadsheet_id,\n",
    "                        range=f'Sheet1!{cell}'\n",
    "                    ).execute()\n",
    "                    \n",
    "                    # Check if cell is empty\n",
    "                    cell_empty = not cell_result.get('values', [])\n",
    "                    \n",
    "                    if cell_empty:\n",
    "                        print(f\"Processing row {i}: {email}\")\n",
    "                        verification_status = verify_email(email)\n",
    "                        \n",
    "                        # Update the cell with the email only if status is Valid\n",
    "                        if verification_status == \"Valid\":\n",
    "                            service.spreadsheets().values().update(\n",
    "                                spreadsheetId=spreadsheet_id,\n",
    "                                range=f'Sheet1!{cell}',\n",
    "                                valueInputOption='RAW',\n",
    "                                body={'values': [[email]]}\n",
    "                            ).execute()\n",
    "                            print(f\"Added verified email: {email}\")\n",
    "                        else:\n",
    "                            # Clear the cell if email is invalid\n",
    "                            service.spreadsheets().values().update(\n",
    "                                spreadsheetId=spreadsheet_id,\n",
    "                                range=f'Sheet1!{cell}',\n",
    "                                valueInputOption='RAW',\n",
    "                                body={'values': [[\"-\"]]}\n",
    "                            ).execute()\n",
    "                            print(f\"Skipped invalid email: {email} (Status: {verification_status})\")\n",
    "                    else:\n",
    "                        print(f\"Skipping row {i}: Email already verified\")\n",
    "                    time.sleep(0.2)  # Rate limiting\n",
    "\n",
    "                    \n",
    "                    \n",
    "        print(\"Email verification completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Update the main function to include email verification\n",
    "def main():\n",
    "    print(\"##############################################\")\n",
    "    # verify_email(\"james.stackhouse@stackedfitness.com.au\")\n",
    "    # verify_email(\"jim.kokkinakis@theeyepractice.com.au\")\n",
    "    # verify_email(\"tanusri@herro.com\")\n",
    "    # verify_email(\"tanusri@fernzz.com\")\n",
    "    print(\"##############################################\")\n",
    "    service = get_google_sheets_service()\n",
    "    spreadsheet_id = '1Xr13JkH27PWV-EKrhh65JtAqGAhtUg1PHJ78Qy4Y8uw'\n",
    "    verify_emails_in_sheet(service, spreadsheet_id)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧪Lead Enrichment\n",
    "\n",
    "### 1. Researching About Prospects company\n",
    "### 2. Crafting personalized offers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "def get_google_sheets_service():\n",
    "   print(\"Starting authentication process...\")\n",
    "   try:\n",
    "       # Load credentials from the service account file\n",
    "       credentials = service_account.Credentials.from_service_account_file(\n",
    "           'credentials.json', \n",
    "           scopes=SCOPES\n",
    "       )\n",
    "       print(\"Successfully loaded service account credentials\")\n",
    "       \n",
    "       # Build the service\n",
    "       service = build('sheets', 'v4', credentials=credentials)\n",
    "       print(\"Successfully created Google Sheets service\")\n",
    "       return service\n",
    "       \n",
    "   except Exception as e:\n",
    "       print(f\"Error during authentication: {str(e)}\")\n",
    "       raise\n",
    "   \n",
    "   \n",
    "def get_column_letter(col_idx):\n",
    "    \"\"\"Convert a 1-based column index to a column letter (e.g., 1 -> A, 27 -> AA).\"\"\"\n",
    "    col_letter = \"\"\n",
    "    while col_idx > 0:\n",
    "        col_idx, remainder = divmod(col_idx - 1, 26)\n",
    "        col_letter = chr(65 + remainder) + col_letter\n",
    "    return col_letter\n",
    "\n",
    "def analyze_with_gpt4(content):\n",
    "    \"\"\"Helper function to make API calls to Azure's GPT-4o-mini\"\"\"\n",
    "    API_KEY = \"\"\n",
    "    ENDPOINT = \"\"\n",
    "    \n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a lead qualification expert. Analyze the provided content and return a JSON response.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                Analyze this website content and provide the following information in JSON format:\n",
    "                Website content: {content[:1000]}\n",
    "                \n",
    "                Please classify this lead with the following details:\n",
    "                1. lead_category: (Hot, Warm, Cold)\n",
    "                2. industry: (specific industry)\n",
    "                3. company_size: (Small, Medium, Large)\n",
    "                4. lead_score: (1-100)\n",
    "                \n",
    "                Base your classification on factors like:\n",
    "                - Company size and scope\n",
    "                - Industry relevance\n",
    "                - Professional language\n",
    "                - Business maturity\n",
    "                \n",
    "                Respond ONLY with a JSON object containing these four fields.\n",
    "            \"\"\"}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 100,\n",
    "        \"response_format\": { \"type\": \"json_object\" }\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"api-key\": API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            ENDPOINT,\n",
    "            headers=headers,\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        print(\"response:\",response)\n",
    "        result = response.json()\n",
    "        print(\"result:\",result['choices'][0]['message']['content'])\n",
    "        return result['choices'][0]['message']['content']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API call error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def enrich_leads(service, spreadsheet_id):\n",
    "    \"\"\"Enrich leads using Azure's GPT-4o-mini to analyze website content\"\"\"\n",
    "    try:\n",
    "        # Get the existing data\n",
    "        range_name = 'Sheet1'\n",
    "        result = service.spreadsheets().values().get(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=range_name\n",
    "        ).execute()\n",
    "        rows = result.get('values', [])\n",
    "        \n",
    "        if not rows:\n",
    "            print('No data found.')\n",
    "            return\n",
    "            \n",
    "        # Find or create necessary columns\n",
    "        header = rows[0]\n",
    "        new_columns = ['lead_category', 'industry', 'company_size', 'lead_score']\n",
    "        \n",
    "        # Add new columns if they don't exist\n",
    "        for column in new_columns:\n",
    "            if column not in header:\n",
    "                header.append(column)\n",
    "                \n",
    "        # Get column indices\n",
    "        website_content_idx = header.index('website_content')\n",
    "        category_idx = header.index('lead_category')\n",
    "        industry_idx = header.index('industry')\n",
    "        size_idx = header.index('company_size')\n",
    "        score_idx = header.index('lead_score')\n",
    "        \n",
    "        # Process each row\n",
    "        for i, row in enumerate(rows[1:], start=2):\n",
    "            if len(row) > website_content_idx and row[website_content_idx].strip():\n",
    "                website_content = row[website_content_idx]\n",
    "                \n",
    "                # Skip if already processed\n",
    "                if len(row) > category_idx and row[category_idx].strip():\n",
    "                    print(f\"Skipping row {i}: Already enriched\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Processing row {i}\")\n",
    "                \n",
    "                try:\n",
    "                    # Get analysis from GPT-4o-mini\n",
    "                    analysis_response = analyze_with_gpt4(website_content)\n",
    "                    analysis = json.loads(analysis_response)\n",
    "                    \n",
    "                    # Update the sheet with enriched data\n",
    "                    updates = [\n",
    "                        [analysis['lead_category']],\n",
    "                        [analysis['industry']],\n",
    "                        [analysis['company_size']],\n",
    "                        [str(analysis['lead_score'])]\n",
    "                    ]\n",
    "                    \n",
    "                    # Update each column\n",
    "                    for col_idx, value in zip(\n",
    "                        [category_idx, industry_idx, size_idx, score_idx],\n",
    "                        updates\n",
    "                    ):\n",
    "                        col_letter = get_column_letter(col_idx + 1)\n",
    "                        service.spreadsheets().values().update(\n",
    "                            spreadsheetId=spreadsheet_id,\n",
    "                            range=f'Sheet1!{col_letter}{i}',\n",
    "                            valueInputOption='RAW',\n",
    "                            body={'values': value}\n",
    "                        ).execute()\n",
    "                    \n",
    "                    print(f\"Successfully enriched row {i}\")\n",
    "                    time.sleep(1)  # Rate limiting\n",
    "                    \n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error parsing API response for row {i}\")\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing row {i}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during lead enrichment: {str(e)}\")\n",
    "\n",
    "# Update the main function\n",
    "def main():\n",
    "    analyze_with_gpt4(\"hello\")\n",
    "    service = get_google_sheets_service()\n",
    "    spreadsheet_id = '1Xr13JkH27PWV-EKrhh65JtAqGAhtUg1PHJ78Qy4Y8uw'\n",
    "    enrich_leads(service, spreadsheet_id)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting authentication process...\n",
      "Successfully loaded service account credentials\n",
      "Successfully created Google Sheets service\n",
      "Added new columns: ['brief_summary', 'key_offerings', 'target_audience', 'unique_value_proposition']\n",
      "Skipping row 2: Already summarized\n",
      "Processing row 3\n",
      "{\n",
      "  \"brief_summary\": \"Optimal Media specializes in scaling home service contractors through targeted Google and Facebook advertising. They focus on eliminating inefficiencies to achieve faster results for their clients.\",\n",
      "  \"key_offerings\": [\n",
      "    \"Google Ads\",\n",
      "    \"Facebook Ads\",\n",
      "    \"Free Consultation\",\n",
      "    \"Free Audit Call\"\n",
      "  ],\n",
      "  \"target_audience\": \"Local service businesses looking to increase sales and customers.\",\n",
      "  \"unique_value_proposition\": \"Their approach avoids formalities and inefficiencies, allowing them to deliver effective advertising solutions tailored specifically for the local service industry.\"\n",
      "}\n",
      "Successfully summarized row 3\n",
      "Processing row 4\n",
      "{\n",
      "  \"brief_summary\": \"Step Digital positions itself as an 'in-house' growth partner, offering exceptional expertise and commitment as an external collaborator. Their focus is on driving results for e-commerce and information product companies through effective direct response social media advertising and conversion funnel optimization.\",\n",
      "  \"key_offerings\": [\n",
      "    \"Direct response social media advertising\",\n",
      "    \"Conversion funnel optimization\",\n",
      "    \"Performance-driven sales strategies\"\n",
      "  ],\n",
      "  \"target_audience\": \"E-commerce and information product companies seeking to enhance their sales and marketing effectiveness.\",\n",
      "  \"unique_value_proposition\": \"They provide disruptive expertise and a strong commitment to driving measurable sales results, backed by trust from numerous top brands.\"\n",
      "}\n",
      "Successfully summarized row 4\n",
      "Processing row 5\n",
      "{\n",
      "  \"brief_summary\": \"Tash Ads offers a solution for staffing and recruiting firms to consistently connect with hiring managers who have active staffing needs. Their Recruitmore® System enables recruiters to fill their pipelines efficiently without the need for cold-calling.\",\n",
      "  \"key_offerings\": [\n",
      "    \"Recruitmore® System\",\n",
      "    \"Free Training\",\n",
      "    \"Lead Generation Strategies\"\n",
      "  ],\n",
      "  \"target_audience\": \"Independent Recruiters and Staffing Firm Owners\",\n",
      "  \"unique_value_proposition\": \"Provides a systematic approach to automate pipeline building and lead generation, reducing manual prospecting efforts and increasing opportunities through digital marketing.\"\n",
      "}\n",
      "Successfully summarized row 5\n",
      "Processing row 6\n",
      "{\n",
      "  \"brief_summary\": \"Meliss offers online marketing and business strategy guidance for coaches, healers, and entrepreneurs, focusing on attracting ideal clients and creating effective content. She emphasizes the importance of smart systems for building a successful and fulfilling business.\",\n",
      "  \"key_offerings\": [\n",
      "    \"Marketing strategies to attract ideal clients\",\n",
      "    \"Content creation guidance\",\n",
      "    \"Time management techniques like time blocking and goal setting\",\n",
      "    \"Access to powerful resources for marketing\"\n",
      "  ],\n",
      "  \"target_audience\": \"Coaches, healers, and entrepreneurs seeking to improve their marketing and business operations.\",\n",
      "  \"unique_value_proposition\": \"Meliss combines intention-driven marketing with practical systems to help clients achieve abundance and freedom in their business.\"\n",
      "}\n",
      "Successfully summarized row 6\n",
      "Processing row 8\n",
      "{\n",
      "  \"brief_summary\": \"Biddyco is a creative agency focused on producing high-quality advertisements for brands looking to scale on platforms like Meta and TikTok. They aim to resolve creative bottlenecks by delivering effective and visually appealing ad content.\",\n",
      "  \"key_offerings\": [\n",
      "    \"Ad creation for Meta\",\n",
      "    \"Ad creation for TikTok\",\n",
      "    \"Creative insights\",\n",
      "    \"Brand identity development\"\n",
      "  ],\n",
      "  \"target_audience\": \"High-growth brands seeking to enhance their advertising performance and brand identity.\",\n",
      "  \"unique_value_proposition\": \"Biddyco combines aesthetic appeal with performance effectiveness in ad creation, ensuring that their clients' brand identity is maintained while driving significant results.\"\n",
      "}\n",
      "Successfully summarized row 8\n",
      "Processing row 9\n",
      "{\n",
      "  \"brief_summary\": \"Denver PPC Agency specializes in digital advertising management, offering services such as Google Ads, Facebook Ads, and Amazon Advertising. They focus on maximizing client revenue and providing measurable results through targeted marketing strategies.\",\n",
      "  \"key_offerings\": [\n",
      "    \"Google Ads Management\",\n",
      "    \"Facebook Ads Management\",\n",
      "    \"Amazon Advertising\",\n",
      "    \"Local SEO (Map Listings)\"\n",
      "  ],\n",
      "  \"target_audience\": \"Business owners seeking to enhance their online presence and increase revenue through effective digital marketing strategies.\",\n",
      "  \"unique_value_proposition\": \"The agency emphasizes clear attribution of sales growth and focuses solely on strategies that drive revenue, setting them apart from competitors who may not provide measurable results.\"\n",
      "}\n",
      "Successfully summarized row 9\n",
      "Processing row 10\n",
      "{\n",
      "  \"brief_summary\": \"The website offers specialized marketing services aimed at helping businesses grow through tailored strategies. With a focus on understanding client needs, they emphasize personalized marketing solutions rather than generic approaches.\",\n",
      "  \"key_offerings\": [\n",
      "    \"Social Media Marketing\",\n",
      "    \"Lead Generation\",\n",
      "    \"Website Design\"\n",
      "  ],\n",
      "  \"target_audience\": \"Businesses looking for effective marketing strategies and lead generation solutions.\",\n",
      "  \"unique_value_proposition\": \"They prioritize customized marketing plans and client collaboration to ensure effective results, differentiating themselves from mindless marketing tactics.\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 191\u001b[0m\n\u001b[0;32m    188\u001b[0m     generate_website_summaries(service, spreadsheet_id)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 191\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 188\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    186\u001b[0m service \u001b[38;5;241m=\u001b[39m get_google_sheets_service()\n\u001b[0;32m    187\u001b[0m spreadsheet_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1Xr13JkH27PWV-EKrhh65JtAqGAhtUg1PHJ78Qy4Y8uw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 188\u001b[0m \u001b[43mgenerate_website_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspreadsheet_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 169\u001b[0m, in \u001b[0;36mgenerate_website_summaries\u001b[1;34m(service, spreadsheet_id)\u001b[0m\n\u001b[0;32m    159\u001b[0m     range_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSheet1!\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_letter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    160\u001b[0m     body \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m: [[value]]  \u001b[38;5;66;03m# Double nested array for single cell\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     }\n\u001b[0;32m    164\u001b[0m     \u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspreadsheets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspreadsheetId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspreadsheet_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalueInputOption\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRAW\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\n\u001b[1;32m--> 169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully summarized row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    172\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Rate limiting\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\googleapiclient\\http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[0;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\googleapiclient\\http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m \u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mredirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[0;32m    236\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httplib2\\__init__.py:1724\u001b[0m, in \u001b[0;36mHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[0;32m   1722\u001b[0m             content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1723\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1724\u001b[0m             (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcachekey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1728\u001b[0m     is_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(e, socket\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httplib2\\__init__.py:1444\u001b[0m, in \u001b[0;36mHttp._request\u001b[1;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[0;32m   1442\u001b[0m     auth\u001b[38;5;241m.\u001b[39mrequest(method, request_uri, headers, body)\n\u001b[1;32m-> 1444\u001b[0m (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auth\u001b[38;5;241m.\u001b[39mresponse(response, body):\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httplib2\\__init__.py:1396\u001b[0m, in \u001b[0;36mHttp._conn_request\u001b[1;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1396\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mBadStatusLine, http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mResponseNotReady):\n\u001b[0;32m   1398\u001b[0m     \u001b[38;5;66;03m# If we get a BadStatusLine on the first try then that means\u001b[39;00m\n\u001b[0;32m   1399\u001b[0m     \u001b[38;5;66;03m# the connection just went stale, so retry regardless of the\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m     \u001b[38;5;66;03m# number of RETRIES set.\u001b[39;00m\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seen_bad_status_line \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import time\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "def get_google_sheets_service():\n",
    "   print(\"Starting authentication process...\")\n",
    "   try:\n",
    "       # Load credentials from the service account file\n",
    "       credentials = service_account.Credentials.from_service_account_file(\n",
    "           'credentials.json', \n",
    "           scopes=SCOPES\n",
    "       )\n",
    "       print(\"Successfully loaded service account credentials\")\n",
    "       \n",
    "       # Build the service\n",
    "       service = build('sheets', 'v4', credentials=credentials)\n",
    "       print(\"Successfully created Google Sheets service\")\n",
    "       return service\n",
    "       \n",
    "   except Exception as e:\n",
    "       print(f\"Error during authentication: {str(e)}\")\n",
    "       raise\n",
    "   \n",
    "   \n",
    "def get_column_letter(col_idx):\n",
    "    \"\"\"Convert a 1-based column index to a column letter (e.g., 1 -> A, 27 -> AA).\"\"\"\n",
    "    col_letter = \"\"\n",
    "    while col_idx > 0:\n",
    "        col_idx, remainder = divmod(col_idx - 1, 26)\n",
    "        col_letter = chr(65 + remainder) + col_letter\n",
    "    return col_letter\n",
    "\n",
    "def analyze_website_content(content):\n",
    "    \"\"\"Helper function to generate website summaries using GPT-4o-mini\"\"\"\n",
    "    API_KEY = \"\"\n",
    "    ENDPOINT = \"\"\n",
    "    \n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert at summarizing website content concisely and professionally.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                Analyze this website content and provide a JSON response with the following:\n",
    "                Website content: {content[:1000]}\n",
    "                \n",
    "                Create a summary with these components:\n",
    "                1. brief_summary: (2-3 sentence overview)\n",
    "                2. key_offerings: (list of main products/services)\n",
    "                3. target_audience: (who the website targets)\n",
    "                4. unique_value_proposition: (what makes them stand out)\n",
    "                \n",
    "                Respond ONLY with a JSON object containing these four fields.\n",
    "            \"\"\"}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 150,\n",
    "        \"response_format\": { \"type\": \"json_object\" }\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"api-key\": API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            ENDPOINT,\n",
    "            headers=headers,\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "\n",
    "        print(result['choices'][0]['message']['content'])\n",
    "        return result['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"API call error: {str(e)}\")\n",
    "        raise\n",
    "def generate_website_summaries(service, spreadsheet_id):\n",
    "    \"\"\"Generate summaries for website content using Azure's GPT-4o-mini\"\"\"\n",
    "    try:\n",
    "        # Get the existing data\n",
    "        range_name = 'Sheet1'\n",
    "        result = service.spreadsheets().values().get(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=range_name\n",
    "        ).execute()\n",
    "        rows = result.get('values', [])\n",
    "        \n",
    "        if not rows:\n",
    "            print('No data found.')\n",
    "            return\n",
    "            \n",
    "        # Find or create necessary columns\n",
    "        header = rows[0]\n",
    "        new_columns = ['brief_summary', 'key_offerings', 'target_audience', 'unique_value_proposition']\n",
    "        columns_added = False\n",
    "        \n",
    "        # Check which columns need to be added\n",
    "        columns_to_add = [col for col in new_columns if col not in header]\n",
    "        if columns_to_add:\n",
    "            # Add new columns to header\n",
    "            header.extend(columns_to_add)\n",
    "            \n",
    "            # Update the header row in the sheet\n",
    "            service.spreadsheets().values().update(\n",
    "                spreadsheetId=spreadsheet_id,\n",
    "                range=f'{range_name}!A1',\n",
    "                valueInputOption='RAW',\n",
    "                body={'values': [header]}\n",
    "            ).execute()\n",
    "            print(f\"Added new columns: {columns_to_add}\")\n",
    "            columns_added = True\n",
    "        \n",
    "        # If columns were added, get fresh data with new structure\n",
    "        if columns_added:\n",
    "            result = service.spreadsheets().values().get(\n",
    "                spreadsheetId=spreadsheet_id,\n",
    "                range=range_name\n",
    "            ).execute()\n",
    "            rows = result.get('values', [])\n",
    "            header = rows[0]\n",
    "                \n",
    "        # Get column indices\n",
    "        website_content_idx = header.index('website_content')\n",
    "        summary_idx = header.index('brief_summary')\n",
    "        offerings_idx = header.index('key_offerings')\n",
    "        audience_idx = header.index('target_audience')\n",
    "        uvp_idx = header.index('unique_value_proposition')\n",
    "        \n",
    "        # Process each row\n",
    "        for i, row in enumerate(rows[1:], start=2):\n",
    "            if len(row) > website_content_idx and row[website_content_idx].strip():\n",
    "                website_content = row[website_content_idx]\n",
    "                \n",
    "                # Skip if already processed\n",
    "                if len(row) > summary_idx and row[summary_idx].strip():\n",
    "                    print(f\"Skipping row {i}: Already summarized\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Processing row {i}\")\n",
    "                \n",
    "                try:\n",
    "                    # Get analysis from GPT-4o-mini\n",
    "                    analysis_response = analyze_website_content(website_content)\n",
    "                    analysis = json.loads(analysis_response)\n",
    "                    \n",
    "                    # Process each field separately\n",
    "                    for col_idx, field in zip(\n",
    "                        [summary_idx, offerings_idx, audience_idx, uvp_idx],\n",
    "                        ['brief_summary', 'key_offerings', 'target_audience', 'unique_value_proposition']\n",
    "                    ):\n",
    "                        col_letter = get_column_letter(col_idx + 1)\n",
    "                        value = str(analysis.get(field, ''))  # Convert to string and handle missing fields\n",
    "                        \n",
    "                        # Update single cell with proper formatting\n",
    "                        range_name = f'Sheet1!{col_letter}{i}'\n",
    "                        body = {\n",
    "                            'values': [[value]]  # Double nested array for single cell\n",
    "                        }\n",
    "                        \n",
    "                        service.spreadsheets().values().update(\n",
    "                            spreadsheetId=spreadsheet_id,\n",
    "                            range=range_name,\n",
    "                            valueInputOption='RAW',\n",
    "                            body=body\n",
    "                        ).execute()\n",
    "                    \n",
    "                    print(f\"Successfully summarized row {i}\")\n",
    "                    time.sleep(1)  # Rate limiting\n",
    "                    \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing API response for row {i}: {e}\")\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing row {i}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during website summarization: {str(e)}\")\n",
    "\n",
    "# Update the main function\n",
    "def main():\n",
    "    service = get_google_sheets_service()\n",
    "    spreadsheet_id = '1Xr13JkH27PWV-EKrhh65JtAqGAhtUg1PHJ78Qy4Y8uw'\n",
    "    generate_website_summaries(service, spreadsheet_id)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
